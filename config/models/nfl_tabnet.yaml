# NFL TabNet Model Configuration
#
# TabNet uses sequential attention to select features at each decision step.
# Provides interpretability through feature importance scores.
#
# Usage:
#   python -m models.training.train_advanced --model tabnet --config config/models/nfl_tabnet.yaml

model_type: tabnet

# Model architecture
architecture:
  n_d: 8               # Width of decision prediction layer
  n_a: 8               # Width of attention embedding
  n_steps: 3           # Number of decision steps
  gamma: 1.3           # Coefficient for feature reusage
  n_independent: 1     # Number of independent GLU layers
  n_shared: 1          # Number of shared GLU layers
  lambda_sparse: 1e-3  # Sparsity regularization

# Training parameters
training:
  learning_rate: 2e-2
  momentum: 0.02       # Batch normalization momentum
  batch_size: 256
  epochs: 100
  patience: 15         # Early stopping patience

# Feature selection
features:
  feature_table: baseline  # Options: baseline, phase2, phase2b
  feature_groups: null     # null = all features, or list like ["form", "epa"]

# Reproducibility
random_state: 42

# Calibration (applied after training)
calibration:
  enabled: true
  method: platt        # Options: platt, isotonic
